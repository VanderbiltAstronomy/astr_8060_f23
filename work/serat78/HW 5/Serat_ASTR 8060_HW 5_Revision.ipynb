{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74e14254",
   "metadata": {},
   "source": [
    "# HW 5\n",
    "-- Serat Saad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30049fd1-aa76-4fef-bb4e-bead537cdef3",
   "metadata": {},
   "source": [
    "<font color='purple'>\n",
    "<b>Feedback:</b>\n",
    "\n",
    "Your notebook has a very nice combination of markdown narrative and code commenting.  These make it really easy to follow your narrative and understand your process. You had a big error at the very beginning of your notebook and it propagated through into everything: your V-band filters were mislabeled and you actually grabbed some H-alpha, some U, and some B. You could have realized it looking at how different the flats were and how some were saturated, but regardless it probably made it difficult to figure out how best to combine the flats since you didn't actually get any stars in those frames. I took off points for this issue once at the beginning, but be aware that all your saved files probably need to be redone before HW6. According to git, your submission was 1 day late. Otherwise, this was a very nice submission!\n",
    "\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e674bca8",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "Here's a revision for HW 5.\n",
    "\n",
    "\n",
    "I revised HW 4R again where I made a mistake while indexing different files for different filters and saving the filter name in the header. I am submitting that revision with this revision. So, I think the filter names should be okay now and the following few cells will properly filter out the V filters.\n",
    "\n",
    "    \n",
    "I also went through the fifth step where I made a mistake while calculating the gain and readnoise. This is the reason why there a lot of variations in gain and read noise. In this revision, I used only flat_fielded flats and calculates gain and read noise again.\n",
    "    \n",
    "\n",
    "This jupyter file size became very large, so I didn't load the images and the cells so that it doesn't get large to upload into github. I have attached a pdf with this submission so that you can go through the outputs.\n",
    "    \n",
    "This is also the reason why I couldn't submit before deadline last time as it wasn't uploading. I tried to use git lfs, but I think the file size is too large this time due to all the images that git lfs is not working.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003c5a90",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ac38dd9",
   "metadata": {},
   "source": [
    "The following two cells will import all the necessary ibraries and directories necessary for the homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3252ac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import block\n",
    "import ccdproc as ccdp\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rc\n",
    "%matplotlib inline\n",
    "from astropy.visualization import hist\n",
    "from ccdproc import ImageFileCollection\n",
    "import ccdproc as ccdp\n",
    "from astropy.modeling import fitting\n",
    "from astropy.modeling.models import Polynomial1D,Chebyshev1D,Legendre1D,Hermite1D\n",
    "from astropy.nddata import CCDData\n",
    "from datetime import datetime\n",
    "from astropy.stats import sigma_clip\n",
    "from astropy.nddata import block_reduce, Cutout2D\n",
    "from astropy.modeling import models\n",
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ccdproc\n",
    "from astropy.nddata import CCDData\n",
    "from ccdproc import subtract_overscan, trim_image, combine\n",
    "from astropy.visualization import hist\n",
    "from astropy.modeling import models\n",
    "\n",
    "from convenience_function import show_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bb02e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Imaging/'            # raw data directory\n",
    "reduced_dir = 'Imaging_reduced/' # reduced working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6cb420",
   "metadata": {},
   "source": [
    "We can start working with the skyflat files to see how different combining methods work for them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bf3569",
   "metadata": {},
   "source": [
    "In the following cell we get all the v filter skyflat images and their files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c26f11-970f-4a48-b628-46ae61bab0c7",
   "metadata": {},
   "source": [
    "<font color='purple'>\n",
    "<b>Comment:</b>\n",
    "    Something has gone wrong, because a019 is not a V-band flat (the log says it is H-alpha). You're going to be combining H-alpha, U, and B band flats using these files.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6869b51b",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "It should be correct this time.    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a791484",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgs = ccdp.ImageFileCollection(reduced_dir,glob_include='*otz.fits') \n",
    "v_flat_files = imgs.files_filtered(imagetyp='skyflat',filter='V',include_path=True) \n",
    "v_flat_imgs  = imgs.filter(imagetyp='skyflat',filter='V') \n",
    "v_flat_imgs.summary\n",
    "v_flat_imgs.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fe3e31",
   "metadata": {},
   "source": [
    "The following cell will plot the v filter flat images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee1ea04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_data = []\n",
    "\n",
    "for i in range(len(v_flat_files)):\n",
    "    with fits.open(v_flat_files[i]) as hdul:\n",
    "        data = hdul[0].data\n",
    "    show_image(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68af5ca2",
   "metadata": {},
   "source": [
    "In the following cell we can find rms values for different methods so that we can compare each of the methods with one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5835178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(file, sigma_clip):\n",
    "    # This function extracts data from a file. It takes two parameters:\n",
    "    # 1. File of the source - file\n",
    "    # 2. Whether we are following the sigma clip method or not - sigma_clip\n",
    "    with fits.open(file) as hdul:\n",
    "        data = hdul[0].data\n",
    "        data /= np.mean(data)\n",
    "        if sigma_clip==True:\n",
    "            sigma, mean = np.std(data), np.mean(data)\n",
    "            data = np.where((data > 2*sigma + mean) | (data < mean - 2*sigma), np.nan, data)\n",
    "        data = np.where(np.isnan(data), np.nanmean(data), data)\n",
    "        return data, np.mean(data)\n",
    "\n",
    "# Processing all files and compute the master flats for sigma clipping\n",
    "all_data_normalized, _ = zip(*(extract_data(file, True) for file in v_flat_files))\n",
    "master_flat_sigma_clip = np.nanmean(all_data_normalized, axis=0)\n",
    "\n",
    "\n",
    "# Processing all files and compute the master flats for other cases\n",
    "all_data, weights = zip(*(extract_data(file, False) for file in v_flat_files))\n",
    "master_flat_mean = np.mean(all_data, axis=0)\n",
    "master_flat_median = np.median(all_data, axis=0)\n",
    "master_flat_weighted = np.average(all_data, axis=0, weights=weights)\n",
    "\n",
    "# Calculating and printing the rms calues\n",
    "\n",
    "rms_mean = np.sqrt(np.mean(master_flat_mean**2))\n",
    "rms_median = np.sqrt(np.mean(master_flat_median**2))\n",
    "rms_sigma_clip = np.sqrt(np.mean(master_flat_sigma_clip**2))\n",
    "rms_weighted = np.sqrt(np.mean(master_flat_weighted**2))\n",
    "\n",
    "print(f\"RMS (mean): {rms_mean}\")\n",
    "print(f\"RMS (median): {rms_median}\")\n",
    "print(f\"RMS (sigma-clipping): {rms_sigma_clip}\")\n",
    "print(f\"RMS (weighted average): {rms_weighted}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad956d5c",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "We can ignore the mean and median method as they are trivial and is not giving a significant advantage comparing to ther methods. Between the sigma-clipping method and the weighted average method, the sigma clip method has less rms value, means the noise is less for this method. We can try this method for other filters. The master flat for this method is plotted in the following cell.\n",
    "    \n",
    "I also tried to combine with different sigma clip intervals. And I found when the range is between +5$\\sigma$ and -3$\\sigma$ , it works the best. But now in this revision, after correcting all the files it looks like when the range is between 2$\\sigma$ or 3$\\sigma$ it works the best. \n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77743045",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_image(master_flat_sigma_clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc72c3e",
   "metadata": {},
   "source": [
    "Now we can get the master flat for each of the filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba790e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = ccdp.ImageFileCollection(reduced_dir,glob_include='*otz.fits') \n",
    "\n",
    "# For V filter\n",
    "v_flat_files = imgs.files_filtered(imagetyp='skyflat',filter='V',include_path=True) \n",
    "all_data, _ = zip(*(extract_data(file, True) for file in v_flat_files))\n",
    "v_master_flat = np.nanmean(all_data, axis=0)\n",
    "\n",
    "# For U filter\n",
    "u_flat_files = imgs.files_filtered(imagetyp='skyflat',filter='U',include_path=True) \n",
    "all_data, _ = zip(*(extract_data(file, True) for file in u_flat_files))\n",
    "u_master_flat = np.nanmean(all_data, axis=0)\n",
    "\n",
    "# For B filter\n",
    "b_flat_files = imgs.files_filtered(imagetyp='skyflat',filter='B',include_path=True) \n",
    "all_data, _ = zip(*(extract_data(file, True) for file in b_flat_files))\n",
    "b_master_flat = np.nanmean(all_data, axis=0)\n",
    "\n",
    "# For R filter\n",
    "r_flat_files = imgs.files_filtered(imagetyp='skyflat',filter='R',include_path=True) \n",
    "all_data, _ = zip(*(extract_data(file, True) for file in r_flat_files))\n",
    "r_master_flat = np.nanmean(all_data, axis=0)\n",
    "\n",
    "# For I filter\n",
    "i_flat_files = imgs.files_filtered(imagetyp='skyflat',filter='I',include_path=True) \n",
    "all_data, _ = zip(*(extract_data(file, True) for file in i_flat_files))\n",
    "i_master_flat = np.nanmean(all_data, axis=0)\n",
    "\n",
    "# For Ha filter\n",
    "ha_flat_files = imgs.files_filtered(imagetyp='skyflat',filter='Ha',include_path=True) \n",
    "all_data, _ = zip(*(extract_data(file, True) for file in ha_flat_files))\n",
    "ha_master_flat = np.nanmean(all_data, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4959c200",
   "metadata": {},
   "source": [
    "Now we can get plot the master falt for each filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66e6ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For V filter\n",
    "show_image(v_master_flat)\n",
    "\n",
    "# For U filter\n",
    "show_image(u_master_flat)\n",
    "\n",
    "# For B filter\n",
    "show_image(b_master_flat)\n",
    "\n",
    "# For R filter\n",
    "show_image(r_master_flat)\n",
    "\n",
    "# For I filter\n",
    "show_image(i_master_flat)\n",
    "\n",
    "# For Ha filter\n",
    "show_image(ha_master_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5347bf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_master_flat = (v_master_flat/np.mean(v_master_flat))\n",
    "u_master_flat = (u_master_flat/np.mean(u_master_flat))\n",
    "b_master_flat = (b_master_flat/np.mean(b_master_flat))\n",
    "r_master_flat = (r_master_flat/np.mean(r_master_flat))\n",
    "i_master_flat = (i_master_flat/np.mean(i_master_flat))\n",
    "ha_master_flat = (ha_master_flat/np.mean(ha_master_flat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458f303b",
   "metadata": {},
   "source": [
    "Now we can divide all the science filed by the normalized master flat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e9f83c",
   "metadata": {},
   "source": [
    "In the following few cells we divide the science image by the master flat, save it, and plot it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed639a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_science_files = imgs.files_filtered(imagetyp='science',filter='V',include_path=True)\n",
    "print(v_science_files)\n",
    "\n",
    "# Plotting and saving for V filter\n",
    "for file in v_science_files:\n",
    "    with fits.open(file) as hdul:\n",
    "        data = hdul[0].data\n",
    "        header = hdul[0].header\n",
    "print(v_science_files)\n",
    "    corrected_data = data / v_master_flat\n",
    "\n",
    "    new_filename = file.replace('.fits', 'f.fits')\n",
    "\n",
    "    fits.writeto(new_filename, corrected_data, header, overwrite=True)\n",
    "    \n",
    "    show_image(corrected_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b393f67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "u_science_files = imgs.files_filtered(imagetyp='science',filter='U',include_path=True)\n",
    "\n",
    "# Plotting and saving for U filter\n",
    "for file in u_science_files:\n",
    "    with fits.open(file) as hdul:\n",
    "        data = hdul[0].data\n",
    "        header = hdul[0].header\n",
    "\n",
    "    corrected_data = data / u_master_flat\n",
    "\n",
    "    new_filename = file.replace('.fits', 'f.fits')\n",
    "\n",
    "    fits.writeto(new_filename, corrected_data, header, overwrite=True)\n",
    "    \n",
    "    show_image(corrected_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbcc373",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b_science_files = imgs.files_filtered(imagetyp='science',filter='B',include_path=True)\n",
    "\n",
    "# Plotting and saving for B filter\n",
    "for file in b_science_files:\n",
    "    with fits.open(file) as hdul:\n",
    "        data = hdul[0].data\n",
    "        header = hdul[0].header\n",
    "\n",
    "    corrected_data = data / b_master_flat\n",
    "\n",
    "    new_filename = file.replace('.fits', 'f.fits')\n",
    "\n",
    "    fits.writeto(new_filename, corrected_data, header, overwrite=True)\n",
    "    \n",
    "    show_image(corrected_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cef9790",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_science_files = imgs.files_filtered(imagetyp='science',filter='R',include_path=True)\n",
    "\n",
    "# Plotting and saving for R filter\n",
    "for file in v_science_files:\n",
    "    with fits.open(file) as hdul:\n",
    "        data = hdul[0].data\n",
    "        header = hdul[0].header\n",
    "\n",
    "    corrected_data = data / r_master_flat\n",
    "\n",
    "    new_filename = file.replace('.fits', 'f.fits')\n",
    "\n",
    "    fits.writeto(new_filename, corrected_data, header, overwrite=True)\n",
    "    \n",
    "    show_image(corrected_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a103a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i_science_files = imgs.files_filtered(imagetyp='science',filter='I',include_path=True)\n",
    "\n",
    "# Plotting and saving for I filter\n",
    "for file in i_science_files:\n",
    "    with fits.open(file) as hdul:\n",
    "        data = hdul[0].data\n",
    "        header = hdul[0].header\n",
    "\n",
    "    corrected_data = data / i_master_flat\n",
    "\n",
    "    new_filename = file.replace('.fits', 'f.fits')\n",
    "\n",
    "    fits.writeto(new_filename, corrected_data, header, overwrite=True)\n",
    "    \n",
    "    show_image(corrected_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a18b29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ha_science_files = imgs.files_filtered(imagetyp='science',filter='Ha',include_path=True)\n",
    "\n",
    "# Plotting and saving for Ha filter\n",
    "for file in i_science_files:\n",
    "    with fits.open(file) as hdul:\n",
    "        data = hdul[0].data\n",
    "        header = hdul[0].header\n",
    "\n",
    "    corrected_data = data / ha_master_flat\n",
    "\n",
    "    new_filename = file.replace('.fits', 'f.fits')\n",
    "\n",
    "    fits.writeto(new_filename, corrected_data, header, overwrite=True)\n",
    "    \n",
    "    show_image(corrected_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5fe9e6",
   "metadata": {},
   "source": [
    "Let's call a few bias and flat flies. Then we can find its mean values, differences between pairs of bias files, and the we can find the gain and read noise of them using the following equations:\n",
    "\n",
    "$$ Gain = \\frac{(\\bar{F1} + \\bar{F2}) - (\\bar{B1} + \\bar{B2})}{\\sigma^{2}_{F1-F2} - \\sigma^{2}_{B1-B2}} $$\n",
    "\n",
    "and, \n",
    "\n",
    "$$ Read \\: Noise = \\frac{Gain \\cdot \\sigma_{B1-B2}}{\\sqrt{2}} $$\n",
    "\n",
    "Where $F1$ and $F2$ are the flat images and $B1$ and $B2$ are the bias images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce58441f-457a-4dc6-8f2a-40467cf5cd6c",
   "metadata": {},
   "source": [
    "<font color='purple'>\n",
    "<b>Comment:</b>\n",
    "    The flat files that you use for this calculation need to be the same (i.e. the counts can't be super different, identical filter). Random pairs of flats need a correction, so that's going to contribute to why your values are so diverse.<br><br>You need to use flat-fielded flats for this, too. This was given in the prompt.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2725f797",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "I went through this part again and clacuated the gain and read noise only for flat_fielded flats.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1104dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the bias and flat files for V filter\n",
    "flat_files = imgs.files_filtered(imagetyp='skyflat',filter='V',include_path=True) \n",
    "bias_files = imgs.files_filtered(imagetyp='bias',include_path=True) \n",
    "\n",
    "\n",
    "gain = []\n",
    "read_noise = []\n",
    "# Selecting a pair in random from two files in random for 100 times, \n",
    "# then going through the pair to get their difference and mean, and std of difference\n",
    "for i in range(100):\n",
    "    flat_pair = random.sample(flat_files, 2)\n",
    "    flat1 = fits.open(flat_pair[0])[0].data\n",
    "    flat2 = fits.open(flat_pair[1])[0].data\n",
    "    \n",
    "\n",
    "    mean_flat = [np.mean(flat1), np.mean(flat2)] # Getting the mean value of the flats\n",
    "    diff_flat = flat1 - flat2\n",
    "    sigma_diff_flat = np.std(diff_flat)\n",
    "    \n",
    "    bias_pair = random.sample(bias_files, 2)\n",
    "    bias1 = fits.open(bias_pair[0])[0].data\n",
    "    bias2 = fits.open(bias_pair[1])[0].data\n",
    "    mean_bias = [np.mean(bias1), np.mean(bias2)] # Getting the mean value of the flats\n",
    "    diff_bias = bias1 - bias2\n",
    "    sigma_diff_bias = np.std(diff_bias)\n",
    "    \n",
    "    # Getting the gain\n",
    "    g = ((mean_flat[0] + mean_flat[1]) - (mean_bias[0] + mean_bias[1]))/(sigma_diff_flat**2 - sigma_diff_bias**2)\n",
    "    gain.append(g)\n",
    "    \n",
    "    # Getting the read_noise\n",
    "    rn = (g * sigma_diff_bias) / math.sqrt(2)\n",
    "    read_noise.append(rn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e77e45",
   "metadata": {},
   "source": [
    "In the following cell we can plot all these 100 gain and read noise values to see how they are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494f8f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_len = np.arange(len(gain))\n",
    "\n",
    "plt.scatter(line_len, gain)\n",
    "plt.xlabel(\"Observation\")\n",
    "plt.ylabel(\"Gain\")\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(line_len, read_noise)\n",
    "plt.xlabel(\"Observation\")\n",
    "plt.ylabel(\"Read Noise\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9857224",
   "metadata": {},
   "source": [
    "We can also find the mean values of these 100 different gain and read noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d4404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_mean_gain = np.mean(gain)\n",
    "v_mean_rn = np.mean(read_noise)\n",
    "\n",
    "print(\"Gain:\", round(v_mean_gain, 3))\n",
    "print(\"Read Noise\", round(v_mean_rn, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1a1b36",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "We can claculate the gain and read noise for the flats of other filters and see how they can be compared between each other:\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360bc1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following function can be helpful so that we don't need to repeat the same proces again.\n",
    "def calculate_gain_and_read_noise(filter_type, imgs, num_iterations=100):\n",
    "    flat_files = imgs.files_filtered(imagetyp='skyflat', filter=filter_type, include_path=True)\n",
    "    bias_files = imgs.files_filtered(imagetyp='bias', include_path=True)\n",
    "\n",
    "    gain = []\n",
    "    read_noise = []\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "\n",
    "        flat_pair = random.sample(flat_files, 2)\n",
    "        flat1 = fits.open(flat_pair[0])[0].data\n",
    "        flat2 = fits.open(flat_pair[1])[0].data\n",
    "\n",
    "        bias_pair = random.sample(bias_files, 2)\n",
    "        bias1 = fits.open(bias_pair[0])[0].data\n",
    "        bias2 = fits.open(bias_pair[1])[0].data\n",
    "\n",
    "        mean_flat = [np.mean(flat1), np.mean(flat2)]\n",
    "        diff_flat = flat1 - flat2\n",
    "        sigma_diff_flat = np.std(diff_flat)\n",
    "\n",
    "        mean_bias = [np.mean(bias1), np.mean(bias2)]\n",
    "        diff_bias = bias1 - bias2\n",
    "        sigma_diff_bias = np.std(diff_bias)\n",
    "\n",
    "        g = ((mean_flat[0] + mean_flat[1]) - (\n",
    "            mean_bias[0] + mean_bias[1])) / (sigma_diff_flat**2 - sigma_diff_bias**2)\n",
    "        gain.append(g)\n",
    "\n",
    "        rn = (g * sigma_diff_bias) / math.sqrt(2)\n",
    "        read_noise.append(rn)\n",
    "\n",
    "    mean_gain = np.mean(gain)\n",
    "    mean_read_noise = np.mean(read_noise)\n",
    "\n",
    "    return mean_gain, mean_read_noise\n",
    "\n",
    "\n",
    "v_gain, v_read_noise = calculate_gain_and_read_noise('V', imgs)\n",
    "u_gain, u_read_noise = calculate_gain_and_read_noise('U', imgs)\n",
    "b_gain, b_read_noise = calculate_gain_and_read_noise('B', imgs)\n",
    "i_gain, i_read_noise = calculate_gain_and_read_noise('I', imgs)\n",
    "r_gain, r_read_noise = calculate_gain_and_read_noise('R', imgs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c440a5",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "           Now we can can compare the gain and read noise in the following cell by printing them:\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321f1879",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Filter Type | Gain | Read Noise\")\n",
    "print(\"------------------------------------\")\n",
    "print(f\"U           | {u_gain:.2f} | {u_read_noise:.2f}\")\n",
    "print(f\"V           | {v_gain:.2f} | {v_read_noise:.2f}\")\n",
    "print(f\"B           | {b_gain:.2f} | {b_read_noise:.2f}\")\n",
    "print(f\"I           | {i_gain:.2f} | {i_read_noise:.2f}\")\n",
    "print(f\"R           | {r_gain:.2f} | {r_read_noise:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d63506",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
